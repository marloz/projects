<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Dimensionality reduction and feature selection | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Dimensionality reduction and feature selection" />
<meta name="author" content="Martynas Lozys" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How to reduce number of inputs while maintaining accuracy?" />
<meta property="og:description" content="How to reduce number of inputs while maintaining accuracy?" />
<link rel="canonical" href="https://marloz.github.io/projects/sklearn/pipeline/feature%20selection/dimensionality%20reduction/2020/04/11/feature-selection.html" />
<meta property="og:url" content="https://marloz.github.io/projects/sklearn/pipeline/feature%20selection/dimensionality%20reduction/2020/04/11/feature-selection.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-11T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Martynas Lozys"},"description":"How to reduce number of inputs while maintaining accuracy?","headline":"Dimensionality reduction and feature selection","@type":"BlogPosting","dateModified":"2020-04-11T00:00:00-05:00","datePublished":"2020-04-11T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://marloz.github.io/projects/sklearn/pipeline/feature%20selection/dimensionality%20reduction/2020/04/11/feature-selection.html"},"url":"https://marloz.github.io/projects/sklearn/pipeline/feature%20selection/dimensionality%20reduction/2020/04/11/feature-selection.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/projects/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://marloz.github.io/projects/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/projects/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Dimensionality reduction and feature selection | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Dimensionality reduction and feature selection" />
<meta name="author" content="Martynas Lozys" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How to reduce number of inputs while maintaining accuracy?" />
<meta property="og:description" content="How to reduce number of inputs while maintaining accuracy?" />
<link rel="canonical" href="https://marloz.github.io/projects/sklearn/pipeline/feature%20selection/dimensionality%20reduction/2020/04/11/feature-selection.html" />
<meta property="og:url" content="https://marloz.github.io/projects/sklearn/pipeline/feature%20selection/dimensionality%20reduction/2020/04/11/feature-selection.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-11T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Martynas Lozys"},"description":"How to reduce number of inputs while maintaining accuracy?","headline":"Dimensionality reduction and feature selection","@type":"BlogPosting","dateModified":"2020-04-11T00:00:00-05:00","datePublished":"2020-04-11T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://marloz.github.io/projects/sklearn/pipeline/feature%20selection/dimensionality%20reduction/2020/04/11/feature-selection.html"},"url":"https://marloz.github.io/projects/sklearn/pipeline/feature%20selection/dimensionality%20reduction/2020/04/11/feature-selection.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://marloz.github.io/projects/feed.xml" title="fastpages" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    // remove paragraph tags in rendered toc (happens from notebooks)
    var toctags = document.querySelectorAll(".toc-entry")
    toctags.forEach(e => (e.firstElementChild.innerText = e.firstElementChild.innerText.replace('¶', '')))
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/projects/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/projects/about/">About Me</a><a class="page-link" href="/projects/search/">Search</a><a class="page-link" href="/projects/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Dimensionality reduction and feature selection</h1><p class="page-description">How to reduce number of inputs while maintaining accuracy?</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-11T00:00:00-05:00" itemprop="datePublished">
        Apr 11, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Martynas Lozys</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/projects/categories/#sklearn">sklearn</a>
        &nbsp;
      
        <a class="category-tags-link" href="/projects/categories/#pipeline">pipeline</a>
        &nbsp;
      
        <a class="category-tags-link" href="/projects/categories/#feature selection">feature selection</a>
        &nbsp;
      
        <a class="category-tags-link" href="/projects/categories/#dimensionality reduction">dimensionality reduction</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/marloz/projects/tree/master/_notebooks/2020-04-11-feature-selection.ipynb" role="button">
<img class="notebook-badge-image" src="/projects/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div><div class="px-2">
    <a href="https://colab.research.google.com/github/marloz/projects/blob/master/_notebooks/2020-04-11-feature-selection.ipynb">
        <img class="notebook-badge-image" src="/projects/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Feature-selection">Feature selection </a></li>
<li class="toc-entry toc-h1"><a href="#Data-exploration">Data exploration </a></li>
<li class="toc-entry toc-h1"><a href="#Sampling">Sampling </a></li>
<li class="toc-entry toc-h1"><a href="#The-benchmark">The benchmark </a></li>
<li class="toc-entry toc-h1"><a href="#In-built-feature-importance">In-built feature importance </a></li>
<li class="toc-entry toc-h1"><a href="#Importance-based-on-correlation-to-target">Importance based on correlation to target </a></li>
<li class="toc-entry toc-h1"><a href="#Permutation-importance">Permutation importance </a></li>
<li class="toc-entry toc-h1"><a href="#Conclusion">Conclusion </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-11-feature-selection.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Feature-selection">
<a class="anchor" href="#Feature-selection" aria-hidden="true"><span class="octicon octicon-link"></span></a>Feature selection<a class="anchor-link" href="#Feature-selection"> </a>
</h1>
<p>The purpose of this post is to explore feature selection techniques, namely:</p>

<pre><code>* Correlation based
* K-best
* In-built features importance of Random Forest
* Permutation importances</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Data-exploration">
<a class="anchor" href="#Data-exploration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data exploration<a class="anchor-link" href="#Data-exploration"> </a>
</h1>
<p>The dataset is taken from Kaggle: <a href="https://www.kaggle.com/c/santander-customer-transaction-prediction">https://www.kaggle.com/c/santander-customer-transaction-prediction</a></p>
<p>Load and inspect data,  check dimensions, data types, missing values, target variable</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'../input/train.csv'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">df_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(200000, 202)
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID_code</th>
      <th>target</th>
      <th>var_0</th>
      <th>var_1</th>
      <th>var_2</th>
      <th>var_3</th>
      <th>var_4</th>
      <th>var_5</th>
      <th>var_6</th>
      <th>var_7</th>
      <th>...</th>
      <th>var_190</th>
      <th>var_191</th>
      <th>var_192</th>
      <th>var_193</th>
      <th>var_194</th>
      <th>var_195</th>
      <th>var_196</th>
      <th>var_197</th>
      <th>var_198</th>
      <th>var_199</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>train_0</td>
      <td>0</td>
      <td>8.9255</td>
      <td>-6.7863</td>
      <td>11.9081</td>
      <td>5.0930</td>
      <td>11.4607</td>
      <td>-9.2834</td>
      <td>5.1187</td>
      <td>18.6266</td>
      <td>...</td>
      <td>4.4354</td>
      <td>3.9642</td>
      <td>3.1364</td>
      <td>1.6910</td>
      <td>18.5227</td>
      <td>-2.3978</td>
      <td>7.8784</td>
      <td>8.5635</td>
      <td>12.7803</td>
      <td>-1.0914</td>
    </tr>
    <tr>
      <th>1</th>
      <td>train_1</td>
      <td>0</td>
      <td>11.5006</td>
      <td>-4.1473</td>
      <td>13.8588</td>
      <td>5.3890</td>
      <td>12.3622</td>
      <td>7.0433</td>
      <td>5.6208</td>
      <td>16.5338</td>
      <td>...</td>
      <td>7.6421</td>
      <td>7.7214</td>
      <td>2.5837</td>
      <td>10.9516</td>
      <td>15.4305</td>
      <td>2.0339</td>
      <td>8.1267</td>
      <td>8.7889</td>
      <td>18.3560</td>
      <td>1.9518</td>
    </tr>
    <tr>
      <th>2</th>
      <td>train_2</td>
      <td>0</td>
      <td>8.6093</td>
      <td>-2.7457</td>
      <td>12.0805</td>
      <td>7.8928</td>
      <td>10.5825</td>
      <td>-9.0837</td>
      <td>6.9427</td>
      <td>14.6155</td>
      <td>...</td>
      <td>2.9057</td>
      <td>9.7905</td>
      <td>1.6704</td>
      <td>1.6858</td>
      <td>21.6042</td>
      <td>3.1417</td>
      <td>-6.5213</td>
      <td>8.2675</td>
      <td>14.7222</td>
      <td>0.3965</td>
    </tr>
    <tr>
      <th>3</th>
      <td>train_3</td>
      <td>0</td>
      <td>11.0604</td>
      <td>-2.1518</td>
      <td>8.9522</td>
      <td>7.1957</td>
      <td>12.5846</td>
      <td>-1.8361</td>
      <td>5.8428</td>
      <td>14.9250</td>
      <td>...</td>
      <td>4.4666</td>
      <td>4.7433</td>
      <td>0.7178</td>
      <td>1.4214</td>
      <td>23.0347</td>
      <td>-1.2706</td>
      <td>-2.9275</td>
      <td>10.2922</td>
      <td>17.9697</td>
      <td>-8.9996</td>
    </tr>
    <tr>
      <th>4</th>
      <td>train_4</td>
      <td>0</td>
      <td>9.8369</td>
      <td>-1.4834</td>
      <td>12.8746</td>
      <td>6.6375</td>
      <td>12.2772</td>
      <td>2.4486</td>
      <td>5.9405</td>
      <td>19.2514</td>
      <td>...</td>
      <td>-1.4905</td>
      <td>9.5214</td>
      <td>-0.1508</td>
      <td>9.1942</td>
      <td>13.2876</td>
      <td>-1.5121</td>
      <td>3.9267</td>
      <td>9.5031</td>
      <td>17.9974</td>
      <td>-8.8104</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 202 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">check_missing</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Missing values </span><span class="si">{</span><span class="n">check_missing</span><span class="p">(</span><span class="n">df_train</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Missing values 0
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_train</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>float64    200
object       1
int64        1
dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">df_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0.10049</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Quite large dataset with 200 numerical features, no missing values and all variable names anonymyzed, target class is inbalanced.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Sampling">
<a class="anchor" href="#Sampling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sampling<a class="anchor-link" href="#Sampling"> </a>
</h1>
<p>In real life scenarios we would want to keep as much information as possible, given resource constraints and probably use model weights instead of downsampling. However, for the purpose of this post, let's downsample majority class to achieve 1:1 ratio, which will both speed up exploration and simplify accuracy measurement.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Drop ID column as it doesn't contain information</span>
<span class="n">df_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'ID_code'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_positive_class</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">df_train</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">df_negative_class</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">df_train</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">df_positive_class</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">sample_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_positive_class</span><span class="p">,</span> <span class="n">df_negative_class</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sample_df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1    20098
0    20098
Name: target, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Separate X and y, add random feature for importance reference, change dtypes to float32 to speedup processing</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">sample_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">'target'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
     <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">))</span>
     <span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">rand</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sample_df</span><span class="o">.</span><span class="n">target</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Create train test splits</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=.</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="The-benchmark">
<a class="anchor" href="#The-benchmark" aria-hidden="true"><span class="octicon octicon-link"></span></a>The benchmark<a class="anchor-link" href="#The-benchmark"> </a>
</h1>
<p>Typical framework for such experiments is building the simplest solution first and then trying different techniques to improve it.
Let's use the usual Random Forest classifier, which is the go-to choice for prototyping, idea testing and experimentation.
We'll fit it on all features to get the benchmark and then try to reduce the number of features while maintaining as high accuracy as possible.
Besides accuracy score, let's keep track of prediction time - a pretend scenario for when real time speed is important, this will add more motivation for dimensionality reduction.
Remember, simple = good :)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="k">def</span> <span class="nf">score_and_time</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">elapsed</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">ts</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Score </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">oob_score_</span><span class="si">}</span><span class="s1">, predicted in </span><span class="si">{</span><span class="n">elapsed</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">baseline</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">baseline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">score_and_time</span><span class="p">(</span><span class="n">baseline</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Score 0.7065244433387238, predicted in 209
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="In-built-feature-importance">
<a class="anchor" href="#In-built-feature-importance" aria-hidden="true"><span class="octicon octicon-link"></span></a>In-built feature importance<a class="anchor-link" href="#In-built-feature-importance"> </a>
</h1>
<p>Random Forest was chosen for another nice property - it has in-built feature importance feature after fitting it, which saves considerable amount of coding.
Let's use already fitted benchmark to get the important features.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">baseline</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">important_cols</span> <span class="o">=</span> <span class="n">importances</span><span class="p">[</span><span class="n">importances</span> <span class="o">&gt;</span> <span class="n">importances</span><span class="p">[</span><span class="s1">'rand'</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Number of features with greater than random column importance </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">important_cols</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">importances</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of features with greater than random column importance 178
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f11ad0854a8&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">reduced_rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">reduced_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">important_cols</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">score_and_time</span><span class="p">(</span><span class="n">reduced_rf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">[</span><span class="n">important_cols</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Score 0.7095720860803583, predicted in 205
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok, so we improved the score somewhat, prediction time is similar, dimensionality is still quite high, around 2/3 of the original input.
Of course, if this was the issue, we could try sacrificing some of the accuracy and choosing less top features, instead of taking all non-random.
Also, importance plot shows exponential decay, so 20/80 principle is applicable here and shouldn't hurt accuracy too much.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Importance-based-on-correlation-to-target">
<a class="anchor" href="#Importance-based-on-correlation-to-target" aria-hidden="true"><span class="octicon octicon-link"></span></a>Importance based on correlation to target<a class="anchor-link" href="#Importance-based-on-correlation-to-target"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another way to perform variable selection that is more traditional and related to linear models is by picking features that are most correlated to target variable.
Since most of the relationships in real world are not linear, we'll use Spearman's rank correlation instead of Pearson's correlation, because it's more robust and better captures non-linearities.
Also, even though pandas has in-built correlation method, let's use scipy's implementation, since it's more efficient.</p>
<p>Some practitioners suggest investigating relationships between features first, because multicollinearity has an effect on importances, i.e. correlated variables will both seem important but contain nearly identical information. But let's leave it for now, because it would unnecessarily complicate implementation if we wanted to automate this process.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.stats</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cor</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">_</span><span class="p">)</span><span class="o">.</span><span class="n">correlation</span><span class="p">),</span>
                   <span class="n">columns</span><span class="o">=</span><span class="n">_</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">_</span><span class="o">.</span><span class="n">columns</span><span class="p">)[</span><span class="s1">'target'</span><span class="p">]</span>
<span class="n">non_rand_corr</span> <span class="o">=</span> <span class="n">cor</span><span class="p">[</span><span class="n">cor</span> <span class="o">&gt;</span> <span class="n">cor</span><span class="p">[</span><span class="s1">'rand'</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Number of variables with correlation to target higher than random </span><span class="si">{</span><span class="n">non_rand_corr</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">cor</span><span class="p">[</span><span class="n">cor</span><span class="o">.</span><span class="n">index</span> <span class="o">!=</span> <span class="s1">'target'</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of variables with correlation to target higher than random 199
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f11ae06b588&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Most of the variables have higher absolute correlation to target than random column, so this heuristic doesn't provide a good variable selection strategy.
Also all variables have very low correlations to target, e.g. 10% at most, so it's not evident how many top variables to select or what correlation threshold to set.
Let's try taking top 20% most correlated variables and see how the score changes.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">top20_cols</span> <span class="o">=</span> <span class="n">cor</span><span class="p">[</span><span class="n">cor</span><span class="o">.</span><span class="n">index</span> <span class="o">!=</span> <span class="s1">'target'</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()[</span><span class="o">-</span><span class="nb">int</span><span class="p">(</span><span class="n">cor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="o">.</span><span class="mi">2</span><span class="p">):]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">rf_corr</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rf_corr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">top20_cols</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Reduced number of columns </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">top20_cols</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">score_and_time</span><span class="p">(</span><span class="n">rf_corr</span><span class="p">,</span> <span class="n">X_test</span><span class="p">[</span><span class="n">top20_cols</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Reduced number of columns 40
Score 0.7037877845503172, predicted in 104
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok, so the score decreased slightly, but we reduced input dimension by 80% and prediction time twice!
Of course here top 20 was chosen arbitrarily, we could do a GridSearch approach and get multiple scores for different number of top variables and see how does the trade-off landscape between accuracy and complexity looks like.</p>
<p>In general, in-built selection is preferrable, because importances are calculated directly when fitting trees, so it saves computation and additional code lines, but in general it's good to know alternative methods for later use with algorithms that don't have in-built feature importance calculation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Permutation-importance">
<a class="anchor" href="#Permutation-importance" aria-hidden="true"><span class="octicon octicon-link"></span></a>Permutation importance<a class="anchor-link" href="#Permutation-importance"> </a>
</h1>
<p>The final technique that I'm going to consider in this post is permutation importance, which as argued (<a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py">https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py</a>) is superior to default impurity based feature importance.</p>
<p>Additionally, I'll wrap feature selection part into Sklearn pipeline, such that it can be integrated into end-to-end solution.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>fit base estimator, in next step get fitted estimator and apply feature importances</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># scikit-learn==0.22.2 or higher required</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span>

<span class="k">class</span> <span class="nc">FeatureSelector</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">ClassifierMixin</span><span class="p">):</span>
    
    <span class="c1"># This can be tuned to accept kwargs for pi</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimator</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">estimator</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">important_cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_important_cols</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">important_cols</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>
        
    <span class="k">def</span> <span class="nf">_get_important_cols</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">pi</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pi</span><span class="o">.</span><span class="n">importances_mean</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'imp'</span><span class="p">])[</span><span class="s1">'imp'</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">importances</span><span class="p">[</span><span class="n">importances</span> <span class="o">&gt;</span> <span class="n">importances</span><span class="p">[</span><span class="s1">'rand'</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">important_cols</span><span class="p">])</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">oob_score_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">oob_score_</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">fs</span> <span class="o">=</span> <span class="n">FeatureSelector</span><span class="p">(</span><span class="n">clf</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Number of selected features </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">fs</span><span class="o">.</span><span class="n">important_cols</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="n">score_and_time</span><span class="p">(</span><span class="n">fs</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Number of selected features 21
Score 0.6743065057843015, predicted in 105
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Conclusion">
<a class="anchor" href="#Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion<a class="anchor-link" href="#Conclusion"> </a>
</h1>
<p>As you can see using permutation importances didn't seem to prove improve accuracy. It reduced the number of columns down to 21, which seems a little low. It could be due to correlated inputs, for more info see here: <a href="https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py">https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance_multicollinear.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-multicollinear-py</a>.
Anyway, it was interesting to implement new Scikit Learn methods, although for practicality I would use in-built importances for dimensionality reduction and then use permutation importances or LIME / SHAP for model interpretation. Additionally, it would be worthwile to play around with automated multicollinearity reduction techniques in the future.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="marloz/projects"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/projects/sklearn/pipeline/feature%20selection/dimensionality%20reduction/2020/04/11/feature-selection.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/projects/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/projects/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/projects/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/projects/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/projects/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
